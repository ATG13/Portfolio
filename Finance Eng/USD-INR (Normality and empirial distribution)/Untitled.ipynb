{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3723b3e-8875-471e-85b1-f82544dc2d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "def check_inr_usd_normality(years_of_data=5):\n",
    "    \"\"\"\n",
    "    Fetches INR-USD data, calculates daily log returns, visualizes their distribution,\n",
    "    and performs statistical normality tests.\n",
    "\n",
    "    Args:\n",
    "        years_of_data (int): The number of years of historical data to fetch.\n",
    "                             Defaults to 5 years.\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting Normality Check for INR-USD Log Returns (last {years_of_data} years) ---\")\n",
    "\n",
    "    # 1. Get the Data\n",
    "    # The ticker 'INR=X' represents the value of 1 USD in Indian Rupees.\n",
    "    ticker = \"INR=X\"\n",
    "    end_date = pd.to_datetime('today').strftime('%Y-%m-%d')\n",
    "    start_date = (pd.to_datetime('today') - pd.DateOffset(years=years_of_data)).strftime('%Y-%m-%d')\n",
    "\n",
    "    print(f\"\\nFetching data for {ticker} from {start_date} to {end_date}...\")\n",
    "    try:\n",
    "        data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        # progress=False hides the download progress bar, making output cleaner\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}. Please check your internet connection or the ticker symbol.\")\n",
    "        return\n",
    "\n",
    "    if data.empty:\n",
    "        print(\"Could not fetch data. The dataframe is empty. This might be due to an invalid ticker or date range.\")\n",
    "        return\n",
    "\n",
    "    print(\"Data fetched successfully. Displaying the first 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    print(f\"\\nTotal data points fetched: {len(data)}\")\n",
    "\n",
    "    # 2. Calculate Log Returns\n",
    "    # Ensure 'Close' column is numeric. Coerce non-numeric values to NaN.\n",
    "    data['Close'] = pd.to_numeric(data['Close'], errors='coerce')\n",
    "    # Drop rows where 'Close' price is NaN, as these cannot be used for return calculation.\n",
    "    data.dropna(subset=['Close'], inplace=True)\n",
    "\n",
    "    if data['Close'].empty:\n",
    "        print(\"No valid 'Close' prices found after cleaning. Cannot calculate returns.\")\n",
    "        return\n",
    "\n",
    "    # Calculate daily log returns: ln(P_t / P_{t-1})\n",
    "    # .shift(1) moves the previous day's close price to the current row.\n",
    "    data['Log_Returns'] = np.log(data['Close'] / data['Close'].shift(1))\n",
    "    # The first row of 'Log_Returns' will be NaN due to .shift(1), so drop it.\n",
    "    data.dropna(subset=['Log_Returns'], inplace=True)\n",
    "\n",
    "    if data['Log_Returns'].empty:\n",
    "        print(\"No valid log returns could be calculated. This can happen if there's only one data point or issues with data quality.\")\n",
    "        return\n",
    "\n",
    "    log_returns = data['Log_Returns']\n",
    "    print(f\"\\nCalculated {len(log_returns)} Log Returns. Displaying basic statistics:\")\n",
    "    print(log_returns.describe())\n",
    "\n",
    "    # 3. Visualize the Distribution\n",
    "    print(\"\\n--- Generating Visualizations (Histogram and Q-Q Plot) ---\")\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Histogram: Shows the frequency distribution of the log returns.\n",
    "    # kde=True adds a Kernel Density Estimate plot, which is a smoothed version of the histogram.\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(log_returns, kde=True, bins=50, color='skyblue')\n",
    "    plt.title(f'Histogram of {ticker} Daily Log Returns', fontsize=14)\n",
    "    plt.xlabel('Log Returns', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.75, linestyle='--')\n",
    "    plt.axvline(log_returns.mean(), color='red', linestyle='dashed', linewidth=1, label=f'Mean: {log_returns.mean():.6f}')\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    # Q-Q Plot (Quantile-Quantile Plot): Compares the quantiles of our data\n",
    "    # against the quantiles of a theoretical normal distribution.\n",
    "    # If data is normal, points should lie on a straight line.\n",
    "    plt.subplot(1, 2, 2)\n",
    "    stats.probplot(log_returns, dist=\"norm\", plot=plt)\n",
    "    plt.title(f'Q-Q Plot of {ticker} Daily Log Returns vs. Normal Distribution', fontsize=14)\n",
    "    plt.xlabel('Theoretical Quantiles (Normal Distribution)', fontsize=12)\n",
    "    plt.ylabel('Ordered Values (Log Returns)', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.tight_layout(pad=3.0) # Adjust layout to prevent overlap of subplots\n",
    "    plt.show()\n",
    "\n",
    "    # 4. Perform Statistical Tests\n",
    "    print(\"\\n--- Performing Statistical Normality Tests ---\")\n",
    "    print(\"Interpretation: For most tests, a p-value > 0.05 suggests the data is normally distributed (Fail to reject H0).\")\n",
    "    print(\"A p-value <= 0.05 suggests the data is NOT normally distributed (Reject H0).\")\n",
    "\n",
    "    # Shapiro-Wilk Test\n",
    "    # This test is generally considered one of the most powerful normality tests.\n",
    "    # H0: The data is normally distributed.\n",
    "    # Ha: The data is not normally distributed.\n",
    "    shapiro_stat, shapiro_p = stats.shapiro(log_returns)\n",
    "    print(f\"\\nShapiro-Wilk Test:\")\n",
    "    print(f\"  Statistic = {shapiro_stat:.6f}, p-value = {shapiro_p:.6f}\")\n",
    "    if shapiro_p > 0.05:\n",
    "        print(\"  Conclusion: Fail to reject H0. Log Returns appear to be normally distributed.\")\n",
    "    else:\n",
    "        print(\"  Conclusion: Reject H0. Log Returns do NOT appear to be normally distributed.\")\n",
    "\n",
    "    # D'Agostino's K-squared Test (Omnibus Test)\n",
    "    # This test is based on skewness and kurtosis.\n",
    "    # H0: The data is normally distributed (i.e., skewness and excess kurtosis are zero).\n",
    "    # Ha: The data is not normally distributed.\n",
    "    k2_stat, k2_p, skewness, kurtosis = stats.normaltest(log_returns)\n",
    "    print(f\"\\nD'Agostino's K-squared (Omnibus) Test:\")\n",
    "    print(f\"  Statistic = {k2_stat:.6f}, p-value = {k2_p:.6f}\")\n",
    "    print(f\"  Calculated Skewness = {skewness:.6f}, Kurtosis = {kurtosis:.6f} (Excess Kurtosis)\")\n",
    "    if k2_p > 0.05:\n",
    "        print(\"  Conclusion: Fail to reject H0. Log Returns appear to be normally distributed.\")\n",
    "    else:\n",
    "        print(\"  Conclusion: Reject H0. Log Returns do NOT appear to be normally distributed.\")\n",
    "\n",
    "    # Kolmogorov-Smirnov Test\n",
    "    # Tests if a sample comes from a specified distribution.\n",
    "    # For normality, we need to provide the mean and standard deviation of the normal distribution.\n",
    "    # H0: The sample data is drawn from a normal distribution with the given parameters.\n",
    "    # Ha: The sample data is not drawn from a normal distribution.\n",
    "    mean_lr = log_returns.mean()\n",
    "    std_lr = log_returns.std()\n",
    "    ks_stat, ks_p = stats.kstest(log_returns, 'norm', args=(mean_lr, std_lr))\n",
    "    print(f\"\\nKolmogorov-Smirnov Test:\")\n",
    "    print(f\"  Statistic = {ks_stat:.6f}, p-value = {ks_p:.6f}\")\n",
    "    if ks_p > 0.05:\n",
    "        print(\"  Conclusion: Fail to reject H0. Log Returns appear to be normally distributed.\")\n",
    "    else:\n",
    "        print(\"  Conclusion: Reject H0. Log Returns do NOT appear to be normally distributed.\")\n",
    "\n",
    "    # Anderson-Darling Test\n",
    "    # This test is a modification of the K-S test and gives more weight to the tails of the distribution.\n",
    "    # It provides critical values for different significance levels.\n",
    "    # H0: The data comes from a specified distribution (here, normal).\n",
    "    # Ha: The data does not come from the specified distribution.\n",
    "    ad_result = stats.anderson(log_returns, dist='norm')\n",
    "    print(f\"\\nAnderson-Darling Test:\")\n",
    "    print(f\"  Statistic = {ad_result.statistic:.6f}\")\n",
    "    for i in range(len(ad_result.critical_values)):\n",
    "        sl, cv = ad_result.significance_level[i], ad_result.critical_values[i]\n",
    "        print(f\"  At {sl:.1f}% significance level, Critical Value = {cv:.6f}\")\n",
    "        if ad_result.statistic < cv:\n",
    "            print(f\"    (Statistic < Critical Value: Data appears normal at {sl:.1f}% significance.)\")\n",
    "        else:\n",
    "            print(f\"    (Statistic > Critical Value: Data does NOT appear normal at {sl:.1f}% significance.)\")\n",
    "\n",
    "    print(\"\\n--- Normality Check Complete ---\")\n",
    "\n",
    "# --- To run the analysis, call the function ---\n",
    "if __name__ == \"__main__\":\n",
    "    # You can adjust the number of years of data to fetch here\n",
    "    check_inr_usd_normality(years_of_data=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
